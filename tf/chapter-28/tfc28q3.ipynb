{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Build, compile, train the sunspot dataset using the LSTM model with callbacks and print the mean absolute error loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Description**:\n",
    "    \n",
    "The dataset consists from 1749/01/01 to 2017/08/31 \n",
    "\n",
    "Load the dataset using pandas \n",
    "\n",
    "Split the dataset into training till 3000 rows and testing sets as remaining \n",
    "\n",
    "By using helper function turn data into a window dataset\n",
    "\n",
    "For inference, we just need to convert the data into multiple samples of predictor variables.\n",
    "\n",
    "For input, we are converting the time series into samples of 60 (window_size). The first 59 data points of a sample will be used as the predictor variables while the last data point will be used as the target variable.\n",
    "\n",
    "Build a sequential model where input layer is Conv1D with 60 filters, kernel size as 5, relu as activation. Add 2 layers of lstm layers with 60 neurons each. Add two dense layers where 30 and 10 neurons respectively. Finally, add lambda layer for scaling output to same range of values\n",
    "\n",
    "Define LearningRateScheduler callback\n",
    "\n",
    "Compile the model using Huber as loss, ‘mae’ as an optimizer, learning rate as 1e-5\n",
    "\n",
    "Train the model using 15 epochs and batch size as 32 and use callbacks\n",
    "\n",
    "Display the absolute mean error loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Level** = Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Format**:\n",
    "Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Format**:\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input** :\n",
    "Sunspot dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : \n",
    "16.218607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
