{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Load, Split and normalize the mnist dataset with Regularisation as l1. Build, compile, train and evaluate the model using SGD optimizer, loss as \"Sparse_categorical_crossentropy\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** : \n",
    "\n",
    "Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
    "\n",
    "Normalize the dataset images by dividing it with 255 for train and test images. \n",
    "\n",
    "Build the mnist dataset model by defining the function as get_regularised_model(wd,rate) using a sequential layer \n",
    "\n",
    "    1. Add the first Dense layer with 128 neurons having kernel regularizer as l1 and relu activation with input shape as x_train. \n",
    "\n",
    "    2. Second layer with dropout  called the argument as step. \n",
    "    \n",
    "    3. The third layer has a Dense layer with 128 neurons and relu activation function and the next layer with dropout called the argument as step. \n",
    "    \n",
    "    4. Repeat the third and fourth layer as 4 times and add next layer has dense with 1 neurons\n",
    "\n",
    "Call the function with momentum as 0.5 and value as 1e-5\n",
    "\n",
    "Compile the model using ‘sgd’ optimizer, loss as \"Sparse_categorical_crossentropy\", metrics as Accuracy and train the model using 5 epochs and validation split as 0.5 and batch size as 32\n",
    "\n",
    "Evaluate the model with testing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** : Mnist dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format** : Neural network model accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample input** : Load the dataset using inbuilt function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : Accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularised_model(wd,rate):\n",
    "    #\n",
    "    # Write your code here\n",
    "    #\n",
    "    #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
